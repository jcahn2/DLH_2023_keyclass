{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07fe2822",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/milesjg2/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../keyclass/')\n",
    "sys.path.append('../scripts/')\n",
    "\n",
    "import argparse\n",
    "import label_data, encode_datasets, train_downstream_model\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "from os.path import join, exists\n",
    "from datetime import datetime\n",
    "import utils\n",
    "import models\n",
    "import create_lfs\n",
    "import train_classifier\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "import itertools\n",
    "from sklearn.metrics import precision_recall_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6283260",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export 'PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07d0d2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file_path = r'../config_files/config_mimic3.yml' # Specify path to the configuration file\n",
    "random_seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "976b4bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bionlp/bluebert_pubmed_mimic_uncased_L-12_H-768_A-12 were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d324ea97a830403b9edf668d3510f87c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "071a5c94ccae44ada05057e0d8b299db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "args = utils.Parser(config_file_path=config_file_path).parse()\n",
    "\n",
    "if args['use_custom_encoder']:\n",
    "    model = models.CustomEncoder(pretrained_model_name_or_path=args['base_encoder'], \n",
    "        device='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "else:\n",
    "    model = models.Encoder(model_name=args['base_encoder'], \n",
    "        device='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "for split in ['train', 'test']:\n",
    "    sentences = utils.fetch_data(dataset=args['dataset'], split=split, path=args['data_path'])\n",
    "    embeddings = model.encode(sentences=sentences, batch_size=args['end_model_batch_size'], \n",
    "                                show_progress_bar=args['show_progress_bar'], \n",
    "                                normalize_embeddings=args['normalize_embeddings'])\n",
    "    with open(join(args['data_path'], args['dataset'], f'{split}_embeddings.pkl'), 'wb') as f:\n",
    "        pickle.dump(embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "151188d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "del model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7308456e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 7,  5, 10,  2,  4]) array([10,  2,  8,  7, 16,  3]) array([7, 2])\n",
      " ... array([ 9, 10, 16,  7,  2])\n",
      " array([ 7,  3,  2, 13, 10,  6,  5,  8,  4,  9]) array([10])]\n"
     ]
    }
   ],
   "source": [
    "args = utils.Parser(config_file_path=config_file_path).parse()\n",
    "\n",
    "train_text = utils.fetch_data(dataset=args['dataset'], path=args['data_path'], split='train')\n",
    "\n",
    "training_labels_present = False\n",
    "if exists(join(args['data_path'], args['dataset'], 'train_labels_all.txt')):\n",
    "    with open(join(args['data_path'], args['dataset'], 'train_labels_all.txt'), 'r') as f:\n",
    "        y_train = f.readlines()\n",
    "    # y_train = np.array([int(i.replace('\\n','')) for i in y_train])\n",
    "    y_train = np.array([np.array([int(i) for i in sub.strip().split()]) for sub in y_train], dtype=object)\n",
    "    print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd62a0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f0c5b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 1],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 1, ..., 0, 0, 1],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "# print(y_train[0])\n",
    "# print(mlb.fit_transform(y_train)[0])\n",
    "# print(mlb.classes_)\n",
    "y_transform = mlb.fit_transform(y_train)\n",
    "type(y_transform)\n",
    "y_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09533a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/milesjg2/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'create_lfs' from '../keyclass/create_lfs.py'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(create_lfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a94f54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting labels for the mimic data...\n",
      "Size of the data: 3922\n",
      "Class distribution (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16]), array([1021,  643, 2666, 1418, 1192,  937,  284, 3079, 1797, 1567, 1577,\n",
      "         13,  440,  742,  200,  300, 1413]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bionlp/bluebert_pubmed_mimic_uncased_L-12_H-768_A-12 were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found assigned category counts [ 7616  6929 13482 11563  6102  5822  2215 30058 11979   687  7085  2541\n",
      "  6894  1949  7479  6713  9065]\n",
      "labeler.vocabulary:\n",
      " 138179\n",
      "labeler.word_indicator_matrix.shape (3922, 510)\n",
      "Len keywords 510\n",
      "assigned_category: Unique and Counts (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16]), array([30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30]))\n",
      "tuberculosis,  found,  unspecified,  bacilli,  tubercle,  bacteriological,  examination,  histological,  specified,  sputum,  confirmed,  microscopy,  infection,  tuberculous,  due,  bacterial,  done,  unknown,  present,  animals,  inoculation,  culture,  histologically,  methods,  acute ['amphetmnneg mthdoneneg pm' 'amphetmnneg mthdonepos'\n",
      " 'bacteriamany yeastnone' 'bacteriamany yeastnone epi'\n",
      " 'bacteriamod yeastnone epi' 'bacteriarare yeastnone'\n",
      " 'bacteriarare yeastnone epi' 'bacterimany yeastnone'\n",
      " 'bacterimod yeastnone' 'csfspinal fluid gram'\n",
      " 'culture routinefinal inpatient' 'culturefinal campylobacter'\n",
      " 'culturefinal inpatient mrsa' 'demerol attendingfirst name'\n",
      " 'epi urine hoursrandom' 'expressed mcgml enterococcus'\n",
      " 'expressed mcgml proteus' 'inrpt pm monthdayyear'\n",
      " 'nameis scan phonetelephonefax' 'namepattern ospital course'\n",
      " 'spherococcasional' 'stainfinal respiratory culturefinal'\n",
      " 'tegretol attendingfirst name' 'wbc bacteriamany yeastnone'\n",
      " 'wbc bacteriarare yeastnone' 'wbc bacterinone yeastnone'\n",
      " 'wbc bacterirare yeastnone' 'yeastmany epi pm' 'yeastnone epi cxr'\n",
      " 'yeastnone epi microbiology']\n",
      "neoplasm,  malignant,  unspecified,  lymph,  nodes,  benign,  sites,  cell,  limb,  site,  hodgkins,  lymphoma,  skin,  carcinoma,  specified,  leukemia,  disease,  tumor,  remission,  lower,  upper,  carcinoid,  face,  situ,  neck ['carcinoma discharge condition' 'cell carcinoma left'\n",
      " 'cell carcinoma right' 'cell carcinoma sp' 'cell carcinoma status'\n",
      " 'ckcpknumeric identifier' 'ct neuts lymphs'\n",
      " 'distention lymphadenopathy lungs' 'farom neg lyphandopathy'\n",
      " 'heent lymphadenopathy' 'lesions lymph cervical'\n",
      " 'lymph cervical axillary' 'lymph node carcinoma' 'lymph node metastasis'\n",
      " 'lymph nodes carcinoma' 'lymphangitic carcinomatosis'\n",
      " 'lymphatics cervical supraclavicular' 'lyphandopathy supra clavicular'\n",
      " 'name stitle drlast' 'name stitle liver' 'name stitle outpatient'\n",
      " 'namepattern measurements left' 'node carcinoma' 'nodes carcinoma'\n",
      " 'nodes malignancy' 'nodes malignancy identified'\n",
      " 'paratracheal lymph node' 'rashes lesions lymph'\n",
      " 'supple lymphadenopathy jugular' 'workup performed paeruginosa']\n",
      "unspecified,  specified,  chronic,  lesion,  female,  kidney,  acute,  glomerulonephritis,  disorders,  genital,  urinary,  cervix,  prostate,  classified,  breast,  disorder,  urethral,  renal,  elsewhere,  diseases,  tract,  disease,  bladder,  vulva,  organs ['amphetmnneg mthdoneneg urine' 'bili pm estgfrusing'\n",
      " 'bilirubinsm urobilngnneg' 'bilirubinsm urobilngnneg ph'\n",
      " 'bilirubneg urobilnneg ph' 'bilirubsm urobiln' 'bilirubsm urobiln ph'\n",
      " 'bilirubsm urobilnneg' 'bilirubsm urobilnneg ph' 'ct chestabdomenpelvis'\n",
      " 'ct chestabdpelvis impression' 'inrpt urine coloryellow'\n",
      " 'name stitle vascular' 'numbness bowelbladder'\n",
      " 'numbness bowelbladder dysfunction' 'paeruginosa saureus beta'\n",
      " 'performed paeruginosa' 'performed paeruginosa saureus'\n",
      " 'rashes jaundice neuro' 'stitle doctor last'\n",
      " 'tingling numbness bowelbladder' 'urine colorstraw appearclear'\n",
      " 'urine coloryellow appearclear' 'urobilngnneg ph'\n",
      " 'urobilngnneg ph leukmod' 'urobilngnneg ph leukneg'\n",
      " 'urobilngnneg ph leuksm' 'urobilnneg ph leukslg' 'urobilnneg ph leukssm'\n",
      " 'urobilnneg ph leukstr']\n",
      "condition,  complication,  unspecified,  antepartum,  mention,  delivered,  without,  care,  episode,  applicable,  postpartum,  pregnancy,  mother,  abortion,  labor,  complicating,  childbirth,  puerperium,  delivery,  complicated,  complications,  associated,  induced,  fetal,  specified ['anesthesia intrapartum fever' 'course issuesystem patient'\n",
      " 'course patient electively' 'female born yearold'\n",
      " 'fever intrapartum antibiotic' 'floor continued postoperative'\n",
      " 'fluid infant emerged' 'girl known lastname' 'history mother yearold'\n",
      " 'hospital course issuesystem' 'ii mother prenatal'\n",
      " 'leading spontaneous vaginal' 'made deliver cesarean'\n",
      " 'maternal fever mother' 'menstruating secondary depoprovera'\n",
      " 'mother yearold' 'ni mother prenatal' 'noted prenatal'\n",
      " 'para mom prenatal' 'para mother prenatal' 'para woman prenatal'\n",
      " 'pregnancyinduced hypertension' 'prior delivery mother'\n",
      " 'required treatment unconjugated' 'time delivery maternal'\n",
      " 'uncomplicated spontaneous onset' 'vaginal delivery yearold'\n",
      " 'vigorous delivery orally' 'whose remaining prenatal'\n",
      " 'yearold female past']\n",
      "due,  unspecified,  dermatitis,  ulcer,  specified,  abscess,  pressure,  cellulitis,  skin,  contact,  erythematous,  condition,  body,  surface,  percent,  involving,  carbuncle,  eczema,  exfoliation,  furuncle,  urticaria,  conditions,  hair,  erythema,  tissue ['cyanosis gross dermatitis' 'dermatomes doctor last'\n",
      " 'diaphoretic eyes conjunctiva' 'erythema drainage discharge'\n",
      " 'erythema drainage pertinent' 'erythema friability'\n",
      " 'excoriations lesions rashes' 'friability erythema'\n",
      " 'gross dermatitis ecchymoses' 'intact erythema drainage'\n",
      " 'intact erythema neuro' 'pulses skin rasheslesions' 'rashes petechiae'\n",
      " 'rashes ulcers' 'rasheslesions ecchymoses'\n",
      " 'rasheslesions ecchymoses neuro' 'rashesno jaundice neuro'\n",
      " 'rashesno jaundiceno' 'reboundguarding extremities'\n",
      " 'rednessbleedingdrainage' 'skin breakdown numbnesstingling'\n",
      " 'skin diffuse erythematous' 'skin rashes ecchymoses'\n",
      " 'skin rashes petechiae' 'skin rasheslesions'\n",
      " 'skin rasheslesions ecchymoses' 'skin rashesno jaundiceno'\n",
      " 'softntnd reboundguarding' 'without erythema exudate'\n",
      " 'wounds infection redness']\n",
      "unspecified,  region,  arthropathy,  joint,  sites,  specified,  associated,  site,  foot,  ankle,  hand,  shoulder,  upper,  pelvic,  forearm,  thigh,  lower,  arm,  leg,  multiple,  acquired,  arthritis,  diseases,  osteoarthrosis,  osteomyelitis ['arthritic' 'cervical axillary inguinal' 'day oxycodoneacetaminophen'\n",
      " 'day oxycodoneacetaminophen mg' 'gout sp arthroscopy'\n",
      " 'guflank costovertebral' 'intraoperative complications postoperatively'\n",
      " 'location un gastaut' 'medical history osteoarthritis'\n",
      " 'name stitle orthopedic' 'name stitle orthopedics'\n",
      " 'noted extremities cce' 'patient admitted orthopaedic'\n",
      " 'patient yearold righthanded' 'patient yo rhanded'\n",
      " 'position sense extremities' 'pvd sp femdoctor' 'right femdoctor'\n",
      " 'right femdoctor last' 'side body followup' 'sounds back costovertebral'\n",
      " 'sp arthroscopy medial' 'stethoscope' 'stitle clinic'\n",
      " 'stitle drlast name' 'stitle orthopedic' 'stitle orthopedics'\n",
      " 'tabsust rel osmotic' 'yearold africanamerican' 'yearold righthanded']\n",
      "congenital,  anomalies,  unspecified,  specified,  anomaly,  cleft,  complete,  deficiency,  incomplete,  longitudinal,  without,  limb,  system,  partial,  syndrome,  lip,  stenosis,  atresia,  palate,  pulmonary,  ear,  spina,  hydrocephalus,  deformities,  region ['abdomen hepatosplenomegaly masses' 'anomalies extremities'\n",
      " 'anomalies hips' 'anomalies hips stable'\n",
      " 'bilaterally cardiovascular normal' 'clavicles summary hospital'\n",
      " 'click sacral dimple' 'cord hepatosplenomegaly normal'\n",
      " 'crescendodecrescendo murmur' 'deformities neuro' 'deformities pulses'\n",
      " 'dermatomes clonus' 'dimple extremities' 'dimple hips'\n",
      " 'dimple hips stable' 'hepatosplenomegaly gu normal' 'hospital dimples'\n",
      " 'ls dermatomes clonus' 'masses hepatosplenomegaly extremities'\n",
      " 'neurology baby appropriate' 'neurology infant appropriate'\n",
      " 'organomegaly noted ext' 'polyvimale first name'\n",
      " 'sacral anomalies extremities' 'sacral anomalies hips' 'supple farom neg'\n",
      " 'symmetrically uvula' 'symmetrically uvula midline' 'wall deformities'\n",
      " 'wall deformities resp']\n",
      "newborn,  fetus,  grams,  fetal,  affecting,  unspecified,  malnutrition,  lightfordates,  without,  due,  mention,  neonatal,  respiratory,  hemorrhage,  maternal,  birth,  perinatal,  placenta,  gestation,  infants,  preterm,  signs,  milk,  breast,  aspiration ['attendinglast name namepattern' 'compazine attendingfirst name'\n",
      " 'due nonreassuring fetal' 'hinitials namepattern last'\n",
      " 'illness yearold righthanded' 'initials namepattern last'\n",
      " 'intubatnot intuba ventspontaneou' 'issuesystem patient yearold'\n",
      " 'name namepattern family' 'namepattern blood' 'namepattern discharge'\n",
      " 'namepattern doctor last' 'namepattern family' 'namepattern hospital'\n",
      " 'namepattern hospital hospital' 'namepattern hospital medical'\n",
      " 'namepattern hospital pediatrics' 'namepattern male'\n",
      " 'namepattern male first' 'namepattern medications'\n",
      " 'namepattern medications admission' 'namepattern ospital'\n",
      " 'namepattern outpatient' 'namepattern per' 'namepattern transplant'\n",
      " 'patient initials namepattern' 'pattern initial namepattern'\n",
      " 'pattern initials namepattern' 'prematurity mother yearold'\n",
      " 'treatment prematurity anthropometric']\n",
      "open,  fracture,  unspecified,  wound,  consciousness,  closed,  intracranial,  loss,  without,  injury,  skull,  mention,  hemorrhage,  hours,  level,  laceration,  prolonged,  conscious,  return,  dislocation,  preexisting,  contusion,  cerebral,  cavity,  bones ['abdomen wcontrast' 'abdomen wcontrast impression' 'abdomen wcontrast pm'\n",
      " 'angap monthdayyear calcium' 'angap pm monthdayyear' 'cc mallincrodt'\n",
      " 'chest wcontrast' 'chest wcontrast impression'\n",
      " 'cleared discharge postoperative' 'cleared drlast name'\n",
      " 'colorstraw appearclear sp' 'coloryellow appearclear sp'\n",
      " 'commentgreen top blood' 'consciousnessalert interactive activity'\n",
      " 'ct abdomen wcontrast' 'ct pelvis wcontrast' 'ct wcontrast'\n",
      " 'name stitle trauma' 'namepattern coma scale' 'pelvis wcontrast'\n",
      " 'pelvis wcontrast pm' 'sp femdoctor last' 'stainfinal emergency hospital'\n",
      " 'stitle within next' 'throughout hospitalization gigufen' 'wcontrast'\n",
      " 'wcontrast impression' 'wcontrast pm impression'\n",
      " 'xs assistcon intubatedintubated' 'xs intubatedintubated ventcontrolled']\n",
      "type,  unspecified,  diabetes,  uncontrolled,  disorders,  deficiency,  manifestations,  stated,  metabolism,  mention,  specified,  mellitus,  secondary,  ii,  juvenile,  without,  goiter,  vitamin,  disorder,  storm,  crisis,  thyrotoxic,  syndrome,  complication,  toxic ['blood glucosegreater th' 'complaint dka major'\n",
      " 'complaint hyperglycemia major' 'course diabetic' 'day glyburide mg'\n",
      " 'dependentdiabetes' 'dependentdiabetes mellitus'\n",
      " 'diabetes mellitus dietcontrolled' 'diabetes type hypertension'\n",
      " 'dietcontrolled' 'discharge diagnosis diabetic' 'dm followed last'\n",
      " 'endocrine patient continued' 'endocrine patient history'\n",
      " 'endocrine patients blood' 'female type diabetes'\n",
      " 'history insulindependent diabetes' 'hospital course diabetic'\n",
      " 'hypertension noninsulindependent' 'insulindependent diabetes'\n",
      " 'insulindependent diabetes mellitus' 'insulindependent diabetic'\n",
      " 'insulindependent dm' 'medical history insulindependent'\n",
      " 'medications metabolic disturbances' 'mellitus dietcontrolled'\n",
      " 'type diabetes since' 'ventcontrolled blood typeart'\n",
      " 'ventcontrolled glucose' 'ventcontrolled pm glucose']\n",
      "anemia,  unspecified,  disease,  deficiency,  specified,  thalassemia,  anemias,  crisis,  blood,  hemolytic,  sicklecell,  neutropenia,  congenital,  due,  iron,  secondary,  chronic,  hereditary,  thrombocytopenia,  without,  hemorrhagic,  disorder,  purpura,  white,  factor ['anisocytnormal poikilocy' 'anisocytnormal poikilocyoccasional'\n",
      " 'blood hypochrnormal anisocy' 'blood hypochrnormal anisocynormal'\n",
      " 'count hypochrom anisocytnormal' 'count hypochromnormal anisocyt'\n",
      " 'hypochrom anisocyt poikilocynormal'\n",
      " 'hypochrom anisocyt poikilocyoccasional'\n",
      " 'hypochrom anisocytnormal poikilocy'\n",
      " 'hypochrom anisocytnormal poikilocynormal'\n",
      " 'hypochromnormal anisocyt poikilocy'\n",
      " 'hypochromnormal anisocyt poikilocynormal'\n",
      " 'hypochromnormal anisocyt poikilocyoccasional'\n",
      " 'hypochromnormal anisocytnormal poikilocynormal'\n",
      " 'hypochromnormal anisocytoccasional'\n",
      " 'hypochromnormal anisocytoccasional poikilocynormal'\n",
      " 'macrocytnormal microcytoccasional'\n",
      " 'macrocytnormal microcytoccasional polychromnormal'\n",
      " 'macrocytoccasional microcytnormal polychromnormal'\n",
      " 'microcynormal polychrnormal blood'\n",
      " 'microcytnormal polychromoccasional pm' 'myelos blood hypochrnormal'\n",
      " 'organismsml alpha hemolytic' 'pm hypochrom anisocytnormal'\n",
      " 'pm hypochromnormal anisocyt' 'pm hypochromnormal anisocytnormal'\n",
      " 'pm hypochromnormal anisocytoccasional'\n",
      " 'poikilocyoccasional macrocytnormal' 'polychromnormal ovalocytoccasional'\n",
      " 'polychromnormal plt smrnormal']\n",
      "disorder,  unspecified,  type,  episode,  remission,  dependence,  schizophrenia,  abuse,  specified,  bipolar,  drug,  acute,  disorders,  current,  chronic,  psychotic,  episodic,  manic,  affective,  recent,  depressive,  continuous,  conduct,  subchronic,  personality ['anxietydepression' 'aox cns iixii' 'assessment deferred psych'\n",
      " 'ativan attendingfirst name' 'bipolar disorder hypertension'\n",
      " 'controlled ativan' 'day klonopin mg' 'day lorazepam mg'\n",
      " 'day quetiapine mg' 'deferred psych listens' 'depression anxiety review'\n",
      " 'depressionanxiety' 'depressionanxiety followed'\n",
      " 'depressionanxiety social' 'depressionanxiety social history'\n",
      " 'fluent psych' 'fluent psych normal' 'haldol attendingfirst'\n",
      " 'haldol attendingfirst name' 'history bipolar disorder'\n",
      " 'history schizoaffective' 'homicidal ideation' 'hospital ativan'\n",
      " 'po bid klonopin' 'po day lorazepam' 'prn trazodone mg' 'psych history'\n",
      " 'psych listens' 'street address depressions'\n",
      " 'suicidal homicidal ideation']\n",
      "migraine,  without,  unspecified,  intractable,  mention,  status,  migrainosus,  elsewhere,  classified,  epilepsy,  sleep,  cerebral,  stated,  diseases,  nerve,  disorder,  aura,  headache,  meningitis,  syndrome,  due,  affecting,  disorders,  side,  chronic ['ambien attendingfirst name' 'complaint nauseavomiting'\n",
      " 'denies feverschills' 'denies nauseavomiting'\n",
      " 'dermatomes clonus reflexes' 'feverchills denies' 'folast name stitle'\n",
      " 'metabolic disturbances infection'\n",
      " 'microcynormal polychrnormal ovalocyoccasional' 'name scmtrapezius'\n",
      " 'name scmtrapezius strength' 'name stitle hypertension'\n",
      " 'name stitle phonetelephonefax' 'nameis md phonetelephonefax'\n",
      " 'nameis phonetelephonefax' 'namepattern md phonetelephonefax'\n",
      " 'neuropsych cns iixii' 'numbness parasthesiae bowel' 'pain feverschills'\n",
      " 'pain nauseavomiting' 'parasthesiae bowel' 'parasthesiae bowel bladder'\n",
      " 'patients pain wellcontrolled' 'polychromoccasional pm'\n",
      " 'scan phonetelephonefax' 'sinitials namepattern'\n",
      " 'sinitials namepattern last' 'stitle phonetelephonefax'\n",
      " 'systems negative fevers' 'yeastnone epi pm']\n",
      "unspecified,  eye,  vision,  impairment,  disorders,  retinal,  corneal,  glaucoma,  acute,  associated,  loss,  ear,  chronic,  otitis,  eyelid,  cataract,  disorder,  body,  visual,  optic,  hearing,  media,  better,  specified,  lesser ['afferent pupillary defect' 'bilaterally fundi' 'dry neuro speech'\n",
      " 'eomi xanicteric' 'eomi xanicteric scleraop' 'exam revealed papilledema'\n",
      " 'eyes ears nose' 'gaze visual facial' 'heent left eye'\n",
      " 'iiiivv eomi ptosis' 'iiiivvi eomi ptosis' 'left eye neck'\n",
      " 'loss vision photophobia' 'ncat pupils mm' 'ophthalmic hospital times'\n",
      " 'papilledema exudates' 'papilledema exudates hemorrhages'\n",
      " 'papilledema iii iv' 'perrla eomi xanicteric' 'poiklo macrocynormal'\n",
      " 'polychrnormal' 'polychrnormal ovalocy' 'polychrnormal ovalocyoccasional'\n",
      " 'reactive light mucous' 'revealed papilledema'\n",
      " 'revealed papilledema exudates' 'rhinorrhea mmm op'\n",
      " 'round reactive extraocular' 'vision diplopia loss' 'xanicteric scleraop']\n",
      "unspecified,  disease,  heart,  chronic,  acute,  infarction,  artery,  embolism,  thrombosis,  kidney,  stage,  failure,  venous,  cerebrovascular,  without,  episode,  care,  effects,  cerebral,  late,  myocardial,  hypertensive,  atherosclerosis,  syndrome,  aneurysm ['allergies lipitor attendingfirst'\n",
      " 'angiographicallyapparent flowlimiting' 'appropriate hemodynamic'\n",
      " 'control patient hemodynamically' 'crescendodecrescendo systolic'\n",
      " 'evidence hemodynamic' 'flowlimiting stenoses' 'flowlimiting stenosis'\n",
      " 'gait disturbance cerebellar' 'given hemodynamic'\n",
      " 'hemodynamically stable neuro' 'hemorrhage discharge condition'\n",
      " 'hypotension atrial' 'infarction doctor last' 'infarction stent'\n",
      " 'name stitle neurosurgery' 'nearcomplete occlusion'\n",
      " 'normal masses thrombi' 'patients hemodynamic'\n",
      " 'prefixes cardiologist primary' 'pressurevolume overload aortic'\n",
      " 'stenosis dissection' 'stenosis mildmoderate'\n",
      " 'stitle cardiologist primary' 'stitle cardiology' 'stitle neurology'\n",
      " 'thrombosis discharge condition' 'type hypertension coronary'\n",
      " 'ventricular pressurevolume overload' 'without evidence hemodynamic']\n",
      "due,  pneumonia,  acute,  unspecified,  chronic,  respiratory,  influenza,  pulmonary,  lung,  asthma,  virus,  sinusitis,  bronchitis,  larynx,  classified,  obstruction,  diseases,  elsewhere,  manifestations,  disease,  identified,  pneumonitis,  interstitial,  without,  allergic ['admission vs temp' 'airway abnormalities schoolage'\n",
      " 'bilateral moderatesized' 'bilateral moderatesized pleural'\n",
      " 'bilaterally anteriorly wheezes' 'cad mildmoderate' 'copdasthma'\n",
      " 'daily albuterol mcgactuation' 'daily fluticasonesalmeterol mcgdose'\n",
      " 'day fluticasonesalmeterol mcgdose' 'exam pulm ctabilat'\n",
      " 'examination respirations comfortable' 'hinitials'\n",
      " 'hinitials namepattern' 'hypertension vegetationmass seen'\n",
      " 'inrpt pm commentsgreen' 'lmnm resistances'\n",
      " 'medications fluticasonesalmeterol mcgdose'\n",
      " 'mildtomoderate pulmonary edema' 'murmursgallopsrubs lung clear'\n",
      " 'murmursgallopsrubs pulm' 'plans daycare rsv' 'po day albuterol'\n",
      " 'times day fluticasonesalmeterol' 'ventilatorassociated'\n",
      " 'ventilatorassociated pneumonia' 'wheezesralesrhonchi' 'wheezesrhonchi'\n",
      " 'wheezingrhonchirales' 'zithromax attendingfirst']\n",
      "unspecified,  obstruction,  without,  mention,  hemorrhage,  ulcer,  chronic,  acute,  perforation,  hernia,  specified,  gangrene,  cholecystitis,  intestine,  gastric,  site,  teeth,  recurrent,  gallbladder,  dental,  jaw,  calculus,  duodenal,  anomalies,  peptic ['abdomen wcontrast study' 'amylase totbili pm'\n",
      " 'appendage lefttoright shunt' 'bleed duodenal' 'bowelbladder'\n",
      " 'bowelbladder dysfunction' 'bowelbladder dysfunction chest'\n",
      " 'crescendodecrescendo' 'gluten attendingfirst'\n",
      " 'gluten attendingfirst name' 'guarding organomegaly gu'\n",
      " 'hepatosplenomegaly ext cce' 'hospital hematemesis'\n",
      " 'including hemorrhage' 'jejunal gastric avms' 'name un gastrostomy'\n",
      " 'nondistended organomegaly masses' 'nontender quadrants reboundguarding'\n",
      " 'organomegaly masses bowel' 'present organomegaly ext'\n",
      " 'room exploratory laparotomy' 'showed duodenal'\n",
      " 'sounds masses distention' 'sp hemorrhoidectomy'\n",
      " 'surgical history hernia' 'tot bili estgfrusing' 'tot prot protcrea'\n",
      " 'totbili blood lipase' 'un gastrostomy' 'vomiting diarrhea past']\n",
      "==== Training the label model ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Computing O...\n",
      "INFO:root:Estimating \\mu...\n",
      "INFO:root:Using GPU...\n",
      "  0%|                                                                               | 0/100 [00:00<?, ?epoch/s]INFO:root:[0 epochs]: TRAIN:[loss=0.028]\n",
      "100%|█████████████████████████████████████████████████████████████████████| 100/100 [03:06<00:00,  1.86s/epoch]\n",
      "INFO:root:Finished Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Model Predictions: Unique value and counts (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16]), array([  71,   84,  404,  162,  107,  106,  150, 1871,   86,   71,   48,\n",
      "         98,   89,  180,   89,  102,  204]))\n",
      "Label Model Training Accuracy 0.5678225395206528\n",
      "Saving results in ../results/mimic/train_label_model_with_ground_truth_04-May-2023-02_42_39.txt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "args = utils.Parser(config_file_path=config_file_path).parse()\n",
    "\n",
    "train_text = utils.fetch_data(dataset=args['dataset'], path=args['data_path'], split='train')\n",
    "\n",
    "training_labels_present = False\n",
    "if exists(join(args['data_path'], args['dataset'], 'train_labels_all.txt')):\n",
    "    with open(join(args['data_path'], args['dataset'], 'train_labels_all.txt'), 'r') as f:\n",
    "        y_train = f.readlines()\n",
    "    y_train = np.array([[int(i) for i in sub.strip().split()] for sub in y_train], dtype=object)\n",
    "    \n",
    "    training_labels_present = True\n",
    "else:\n",
    "    y_train = None\n",
    "    training_labels_present = False\n",
    "    print('No training labels found!')\n",
    "\n",
    "with open(join(args['data_path'], args['dataset'], f'train_embeddings.pkl'), 'rb') as f:\n",
    "    X_train = pickle.load(f)\n",
    "\n",
    "# Convert to MultiLabel format\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_train_ml = mlb.fit_transform(y_train)\n",
    "\n",
    "# Print dataset statistics\n",
    "print(f\"Getting labels for the {args['dataset']} data...\")\n",
    "print(f'Size of the data: {len(train_text)}')\n",
    "if training_labels_present:\n",
    "    print('Class distribution', np.unique(np.hstack(y_train.flatten()), return_counts=True))\n",
    "class_balance = np.unique(np.hstack(y_train.flatten()), return_counts=True)[1] / np.unique(np.hstack(y_train.flatten()), return_counts=True)[1].sum()\n",
    "# Load label names/descriptions\n",
    "label_names = []\n",
    "for a in args:\n",
    "    if 'target' in a: label_names.append(args[a])\n",
    "\n",
    "\n",
    "        \n",
    "# Creating labeling functions\n",
    "labeler = create_lfs.CreateLabellingFunctions(custom_encoder=args['use_custom_encoder'],\n",
    "                                              base_encoder=args['base_encoder'], \n",
    "                                            device=torch.device(args['device']),\n",
    "                                            label_model=args['label_model'])\n",
    "# obtain predicted probabilities and labels from label model\n",
    "proba_preds, y_preds = labeler.get_labels(text_corpus=train_text, label_names=label_names, max_df = 1.0, min_df=0.001, \n",
    "                                ngram_range=(1,3), topk=args['topk'], y_train=y_train_ml, \n",
    "                                label_model_lr=args['label_model_lr'], label_model_n_epochs=args['label_model_n_epochs'], \n",
    "                                verbose=True, n_classes=args['n_classes'], class_balance=class_balance, min_topk=False)\n",
    "\n",
    "y_train_pred = y_preds\n",
    "\n",
    "\n",
    "# Save the predictions\n",
    "if not os.path.exists(args['preds_path']): os.makedirs(args['preds_path'])\n",
    "with open(join(args['preds_path'], f\"{args['label_model']}_proba_preds.pkl\"), 'wb') as f:\n",
    "    pickle.dump(proba_preds, f)\n",
    "\n",
    "# Print statistics\n",
    "print('Label Model Predictions: Unique value and counts', np.unique(\n",
    "    y_preds.flatten(), return_counts=True\n",
    "))\n",
    "if training_labels_present:\n",
    "    print('Label Model Training Accuracy', np.mean([(y_train_pred[i] in labels) for i,labels in enumerate(y_train)]))\n",
    "\n",
    "\n",
    "    # Log the metrics\n",
    "    training_metrics_with_gt = utils.compute_metrics(y_preds=y_train_pred, y_true=y_train, average=args['average'])\n",
    "    utils.log(metrics=training_metrics_with_gt, filename='label_model_with_ground_truth', \n",
    "        results_dir=args['results_path'], split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15b134d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "del labeler\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4705c413",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "def custom_train(model, device, X_train, y_train, epochs, batch_size, lr):\n",
    "    if isinstance(y_train, np.ndarray):\n",
    "        y_train = torch.from_numpy(y_train)\n",
    "\n",
    "    if isinstance(X_train, np.ndarray):\n",
    "        X_train = torch.from_numpy(X_train)\n",
    "        \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                 lr=lr)\n",
    "    N = len(X_train)\n",
    "    pbar = trange(epochs, unit=\"batch\")\n",
    "    for nep in pbar:\n",
    "        pbar.set_description(f\"Epoch {nep}\")\n",
    "        permutation = torch.randperm(N)\n",
    "        running_loss = 0.0\n",
    "        for i in range(0, N, batch_size):\n",
    "            optimizer.zero_grad()\n",
    "            indices = permutation[i:i + batch_size]\n",
    "\n",
    "            batch_x, batch_y = X_train[indices], y_train[indices]\n",
    "            batch_y = batch_y.to(device)\n",
    "            batch_x = batch_x.to(device)\n",
    "            \n",
    "            out = model.forward(batch_x, mode='inference', raw_text=False)\n",
    "            loss = criterion(out, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss = running_loss + (loss.cpu().detach().numpy() *\n",
    "                                           batch_size / N)\n",
    "        print(running_loss)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "882f6a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be494dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence of least confident data point of class 0: 0.05293172274353259\n",
      "Confidence of least confident data point of class 1: 0.8517329214149676\n",
      "Confidence of least confident data point of class 2: 0.9962841604905776\n",
      "Confidence of least confident data point of class 3: 0.7814581440263394\n",
      "Confidence of least confident data point of class 4: 0.21091249901671633\n",
      "Confidence of least confident data point of class 5: 0.631550790285461\n",
      "Confidence of least confident data point of class 6: 0.9917990024352776\n",
      "Confidence of least confident data point of class 7: 0.9330492741922651\n",
      "Confidence of least confident data point of class 8: 0.09316190574939086\n",
      "Confidence of least confident data point of class 9: 0.08123801130177821\n",
      "Confidence of least confident data point of class 10: 0.08175644149515268\n",
      "Confidence of least confident data point of class 11: 0.9999999999051195\n",
      "Confidence of least confident data point of class 12: 0.9578520456979125\n",
      "Confidence of least confident data point of class 13: 0.9862604953461629\n",
      "Confidence of least confident data point of class 14: 0.951541919644817\n",
      "Confidence of least confident data point of class 15: 0.968305927640448\n",
      "Confidence of least confident data point of class 16: 0.8570378600761503\n",
      "\n",
      "==== Data statistics ====\n",
      "Size of training data: (3922, 768), testing data: (1308, 768)\n",
      "Size of testing labels: (1308,)\n",
      "Size of training labels: (3922,)\n",
      "Training class distribution (ground truth): [0.00025497 0.00025497 0.00025497 ... 0.00025497 0.00025497 0.00025497]\n",
      "Training class distribution (label model predictions): [0.00025497 0.00025497 0.00025497 ... 0.00025497 0.00025497 0.00025497]\n",
      "\n",
      "KeyClass only trains on the most confidently labeled data points! Applying mask...\n",
      "\n",
      "==== Data statistics (after applying mask) ====\n",
      "Size of training data: (1912, 768)\n",
      "Size of training labels: (1912,)\n",
      "Training class distribution (ground truth): [0.00052301 0.00052301 0.00052301 ... 0.00052301 0.00052301 0.00052301]\n",
      "Training class distribution (label model predictions): [0.00052301 0.00052301 0.00052301 ... 0.00052301 0.00052301 0.00052301]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bionlp/bluebert_pubmed_mimic_uncased_L-12_H-768_A-12 were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Training the downstream classifier =====\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|█████████| 20/20 [00:02<00:00,  9.33batch/s, best_loss=0.2, running_loss=0.2, tolerance_count=0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.utils import shuffle\n",
    "args = utils.Parser(config_file_path=config_file_path).parse()\n",
    "\n",
    "# Set random seeds\n",
    "random_seed = random_seed\n",
    "torch.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "X_train_embed_masked, y_train_lm_masked, y_train_masked, \\\n",
    "\tX_test_embed, y_test, training_labels_present, \\\n",
    "\tsample_weights_masked, proba_preds_masked = train_downstream_model.load_data_all(args, class_balance=class_balance, max_num=2000)\n",
    "\n",
    "# X_train_embed_masked = normalize(X_train_embed_masked)\n",
    "# X_test_embed = normalize(X_test_embed)\n",
    "# with open(join(args['data_path'], args['dataset'], f'train_embeddings.pkl'), 'rb') as f:\n",
    "#     X_train = pickle.load(f)\n",
    "# Train a downstream classifier\n",
    "\n",
    "\n",
    "if args['use_custom_encoder']:\n",
    "\tencoder = models.CustomEncoder(pretrained_model_name_or_path=args['base_encoder'], device=args['device'])\n",
    "else:\n",
    "\tencoder = models.Encoder(model_name=args['base_encoder'], device=args['device'])\n",
    "    \n",
    "\n",
    "classifier = models.FeedForwardTCN(encoder_model=encoder,\n",
    "\t\t\t\t\t\t\t\t\t\tnum_inputs=768, \n",
    "\t\t\t\t\t\t\t\t\t\tnum_channels1=[128, 128, 128], \n",
    "\t\t\t\t\t\t\t\t\t\tnum_channels2=[64, 64, 64],\n",
    "\t\t\t\t\t\t\t\t\t\th_sizes=[128,64],\n",
    "\t\t\t\t\t\t\t\t\t\tkernel_size=3, \n",
    "\t\t\t\t\t\t\t\t\t\tdropout=0.1, \n",
    "\t\t\t\t\t\t\t\t\t\tbatch_size=512, \n",
    "\t\t\t\t\t\t\t\t\t\tdevice=torch.device(args['device']))\n",
    "# classifier = models.FeedForwardFlexible(encoder_model=encoder,\n",
    "# \t\t\t\t\t\t\t\t\t\th_sizes=[768, 1024, 512, 256, 64, 256, 512, 1024, 64, 17], \n",
    "# \t\t\t\t\t\t\t\t\t\tactivation=eval(args['activation']),\n",
    "# \t\t\t\t\t\t\t\t\t\tdevice=torch.device(args['device']))\n",
    "\n",
    "\n",
    "print('\\n===== Training the downstream classifier =====\\n')\n",
    "X_train_embed_masked, y_train_lm_masked = shuffle(X_train_embed_masked, y_train_lm_masked, random_state=2)\n",
    "\n",
    "model = train_classifier.train_multi_label(model=classifier, \n",
    "\t\t\t\t\t\t\tdevice=torch.device(args['device']),\n",
    "\t\t\t\t\t\t\tX_train=X_train_embed_masked, \n",
    "\t\t\t\t\t\t\ty_train=y_train_lm_masked,\n",
    "\t\t\t\t\t\t\tsample_weights=sample_weights_masked if args['use_noise_aware_loss'] else None, \n",
    "\t\t\t\t\t\t\tepochs=args['end_model_epochs'], \n",
    "\t\t\t\t\t\t\tbatch_size=512, \n",
    "\t\t\t\t\t\t\tcriterion=eval(args['criterion']), \n",
    "\t\t\t\t\t\t\traw_text=False, \n",
    "\t\t\t\t\t\t\tlr=0.001, \n",
    "\t\t\t\t\t\t\tweight_decay=0,\n",
    "\t\t\t\t\t\t\tpatience=args['end_model_patience'])\n",
    "\n",
    "end_model_preds_train = model.predict_proba(torch.from_numpy(X_train_embed_masked), batch_size=512, raw_text=False)\n",
    "end_model_preds_test = model.predict_proba(torch.from_numpy(X_test_embed), batch_size=512, raw_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "625d00ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|█| 1/1 [00:01<00:00,  1.10s/batch, self_train_agreement=0.844, tolerance_count=0, validation_accu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.2635968 , 0.27614966, 0.36435422, ..., 0.17386761, 0.19087194,\n",
       "        0.3986823 ],\n",
       "       [0.23661907, 0.27418262, 0.22898012, ..., 0.09838374, 0.19112627,\n",
       "        0.34077525],\n",
       "       [0.04292928, 0.12411701, 0.18535729, ..., 0.04165442, 0.03059874,\n",
       "        0.1658059 ],\n",
       "       ...,\n",
       "       [0.0346226 , 0.02063135, 0.21299645, ..., 0.00964527, 0.01055443,\n",
       "        0.0689842 ],\n",
       "       [0.02287608, 0.03450003, 0.16921255, ..., 0.00537035, 0.01754055,\n",
       "        0.05892736],\n",
       "       [0.01842624, 0.01368896, 0.4027123 , ..., 0.02738493, 0.03685291,\n",
       "        0.03441577]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\n",
    "        join(args['data_path'], args['dataset'], f'train_embeddings.pkl'),\n",
    "        'rb') as f:\n",
    "    X_train_embed = pickle.load(f)\n",
    "with open(join(args['data_path'], args['dataset'], f'test_embeddings.pkl'),\n",
    "          'rb') as f:\n",
    "    X_test_embed = pickle.load(f)\n",
    "\n",
    "model = train_classifier.self_train(model=model, \n",
    "\t\t\t\t\t\t\t\t\tX_train=X_train_embed, \n",
    "\t\t\t\t\t\t\t\t\tX_val=X_test_embed, \n",
    "\t\t\t\t\t\t\t\t\ty_val=y_test, \n",
    "\t\t\t\t\t\t\t\t\tdevice=torch.device(args['device']), \n",
    "\t\t\t\t\t\t\t\t\tlr=eval(args['self_train_lr']), \n",
    "\t\t\t\t\t\t\t\t\tweight_decay=eval(args['self_train_weight_decay']),\n",
    "\t\t\t\t\t\t\t\t\tpatience=args['self_train_patience'], \n",
    "\t\t\t\t\t\t\t\t\tbatch_size=args['self_train_batch_size'], \n",
    "\t\t\t\t\t\t\t\t\tq_update_interval=args['q_update_interval'],\n",
    "\t\t\t\t\t\t\t\t\tself_train_thresh=eval(args['self_train_thresh']), \n",
    "\t\t\t\t\t\t\t\t\tprint_eval=True,\n",
    "\t\t\t\t\t\t\t\t\traw_text=False, \n",
    "\t\t\t\t\t\t\t\t\ttrain_multilabel=True)\n",
    "\n",
    "X_test_embed = torch.from_numpy(X_test_embed)\n",
    "\n",
    "##This is 1/2  what you should return. ONE RETURN FOR FEED FORWARD, ONE FOR TCN\n",
    "model.forward(torch.tensor(X_train_embed).to(\"cuda\"), raw_text=False).cpu().detach().numpy()\n",
    "\n",
    "\n",
    "#IGNORE THIS\n",
    "# end_model_preds_test = model.predict(X_test_embed, batch_size=args['self_train_batch_size'], raw_text=False)\n",
    "\n",
    "\n",
    "# # Print statistics\n",
    "# testing_metrics = utils.compute_metrics_bootstrap(y_preds=end_model_preds_test,\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\t\ty_true=y_test, \n",
    "# \t\t\t\t\t\t\t\t\t\t\t\t\taverage=args['average'], \n",
    "# \t\t\t\t\t\t\t\t\t\t\t\t\tn_bootstrap=args['n_bootstrap'], \n",
    "# \t\t\t\t\t\t\t\t\t\t\t\t\tn_jobs=args['n_jobs'], \n",
    "# \t\t\t\t\t\t\t\t\t\t\t\t\tmultilabel=True)\n",
    "# print(testing_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3a82e7",
   "metadata": {},
   "source": [
    "### DONT WORRY ABOUT BEYOND THIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3acb0397",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_cust_thresholds(model, X_train, X_test, y_train, y_test):\n",
    "    model.eval()\n",
    "    np.random.RandomState(1234)\n",
    "\n",
    "    \n",
    "    repeats = [len(x) for x in y_train]\n",
    "    y_train_multi = np.array(list(itertools.chain.from_iterable(y_train)))\n",
    "    y_pred_train = model.forward(torch.tensor(X_train).to(\"cuda\"), raw_text=False).cpu().detach().numpy()\n",
    "    y_pred_train_multi = np.repeat(y_pred_train,repeats,axis=0)\n",
    "    \n",
    "    _, n_classes = y_pred_train_multi.shape\n",
    "    overall_thresholds = []\n",
    "    for i in range(n_classes):\n",
    "        \n",
    "        # Computing best threshold for i-th class\n",
    "        precision, recall, thresholds = precision_recall_curve(y_train_multi, y_pred_train_multi[:, i], pos_label=i)\n",
    "\n",
    "        # compute f-1\n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "        # pick up the best threshold's index\n",
    "        best_idx = np.argmax(f1)\n",
    "        overall_thresholds.append(thresholds[best_idx])\n",
    "    \n",
    "    overall_thresholds = np.array(overall_thresholds)\n",
    "    y_pred_test = model.forward(X_test_embed.to(\"cuda\"), raw_text=False).cpu().detach().numpy()\n",
    "    y_pred_bool = y_pred_test > overall_thresholds[None,:]\n",
    "    return y_pred_bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18da00eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_accuracy(y_pred, y_true):\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    y_true = mlb.fit_transform(y_true)\n",
    "    actual_pos_sum = y_true.sum(axis=0)\n",
    "    pred_pos_sum = y_pred.sum(axis=0)\n",
    "    pred_actual_intersect = (y_true&y_pred).sum(axis=0)\n",
    "    \n",
    "    class_precision = np.nan_to_num(pred_actual_intersect/pred_pos_sum)\n",
    "    overall_precision = pred_actual_intersect.sum() / pred_pos_sum.sum()\n",
    "    class_recall = np.nan_to_num(pred_actual_intersect/actual_pos_sum)\n",
    "    overall_recall = pred_actual_intersect.sum() / actual_pos_sum.sum()\n",
    "    \n",
    "    class_accuracy = (y_true==y_test_pred).sum(axis=0) / y_true.shape[0]\n",
    "    overall_accuracy = (y_true==y_test_pred).sum() / (y_true.shape[0] * y_true.shape[1])\n",
    "    \n",
    "    return class_precision, class_recall, class_accuracy, overall_precision, overall_recall, overall_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af15e90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in true_divide\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in true_divide\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in true_divide\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in true_divide\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in true_divide\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in true_divide\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in true_divide\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in true_divide\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in true_divide\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in true_divide\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in true_divide\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in true_divide\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.33333333, 0.        , 0.66488141, 0.        , 0.29266282,\n",
       "        0.25519288, 0.        , 0.80169101, 0.        , 0.33333333,\n",
       "        0.4078643 , 0.        , 0.2       , 0.2       , 0.        ,\n",
       "        0.        , 0.        ]),\n",
       " array([0.00275482, 0.        , 0.99885057, 0.        , 0.92447917,\n",
       "        0.77945619, 0.        , 0.99428027, 0.        , 0.00193798,\n",
       "        0.9906367 , 0.        , 0.00675676, 0.0045045 , 0.        ,\n",
       "        0.        , 0.        ]),\n",
       " array([0.72171254, 0.83944954, 0.66437309, 0.62691131, 0.32186544,\n",
       "        0.36850153, 0.91896024, 0.79816514, 0.54434251, 0.60474006,\n",
       "        0.40902141, 0.87155963, 0.88455657, 0.82798165, 0.93654434,\n",
       "        0.93807339, 0.60474006]),\n",
       " 0.4834782608695652,\n",
       " 0.47147702744372494,\n",
       " 0.6989116747616477)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred = predict_on_cust_thresholds(model, X_train_embed, X_test_embed, y_train, y_test)\n",
    "precision_recall_accuracy(y_test_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525841ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
